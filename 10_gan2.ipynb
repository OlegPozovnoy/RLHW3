{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "10-gan2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlegPozovnoy/RLHW3/blob/master/10_gan2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGP6vN_idPnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eeef4e7-0c85-4ede-ca73-f269d3583f56"
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.stats as st\n",
        "import scipy.integrate as integrate\n",
        "from scipy.stats import multivariate_normal\n",
        "from sklearn import linear_model\n",
        "from sklearn.utils.testing import ignore_warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import statsmodels.api as sm\n",
        "from matplotlib.colors import LogNorm\n",
        "import pickle\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "\n",
        "import cProfile\n",
        "from datetime import datetime\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_palette(\"colorblind\")\n",
        "palette = sns.color_palette()\n",
        "figsize = (15,8)\n",
        "legend_fontsize = 16\n",
        "\n",
        "from matplotlib import rc\n",
        "#rc('font',**{'family':'sans-serif'})\n",
        "#rc('text', usetex=True)\n",
        "#rc('text.latex',preamble=r'\\usepackage[utf8]{inputenc}')\n",
        "#rc('text.latex',preamble=r'\\usepackage[russian]{babel}')\n",
        "#rc('figure', **{'dpi': 300})"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ2MHWmpdPnt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.utils import make_grid"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaWoXO_GdPnt"
      },
      "source": [
        "## Pix2Pix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLQYN9TWd_Dk",
        "outputId": "dc874aa0-b757-416b-c434-dd9d360f1561"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxybPVpDdPny"
      },
      "source": [
        "def plot_losses(d_losses, g_losses):\n",
        "    fig = plt.figure(figsize=(12, 8))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    n_epochs = len(d_losses) - 1\n",
        "    x_train = np.linspace(0, n_epochs, len(d_losses))\n",
        "    x_test = np.arange(n_epochs + 1)\n",
        "\n",
        "    ax.plot(x_train, d_losses, label='Ошибка дискриминатора')\n",
        "    ax.plot(x_test, g_losses, label='Ошибка генератора')\n",
        "    ax.legend()\n",
        "    plt.xlabel('Эпоха обучения')\n",
        "    plt.ylabel('Ошибка')\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ekIgaFUM_zY"
      },
      "source": [
        "\n",
        "class ConvBlock(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size, kernel_size=4, stride=2, padding=1, activation=True, batch_norm=True):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(input_size, output_size, kernel_size, stride, padding)\n",
        "        self.activation = activation\n",
        "        self.lrelu = torch.nn.LeakyReLU(0.2, True)\n",
        "        self.batch_norm = batch_norm\n",
        "        self.bn = torch.nn.BatchNorm2d(output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.activation:\n",
        "            out = self.conv(self.lrelu(x))\n",
        "        else:\n",
        "            out = self.conv(x)\n",
        "\n",
        "        if self.batch_norm:\n",
        "            return self.bn(out)\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "class DeconvBlock(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size, kernel_size=4, stride=2, padding=1, batch_norm=True):\n",
        "        super(DeconvBlock, self).__init__()\n",
        "        self.deconv = torch.nn.ConvTranspose2d(input_size, output_size,\n",
        "                                               kernel_size, stride, padding)\n",
        "        self.bn = torch.nn.BatchNorm2d(output_size)\n",
        "        self.drop = torch.nn.Dropout(0.25)\n",
        "        self.relu = torch.nn.ReLU(True)\n",
        "        self.batch_norm = batch_norm\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.batch_norm:\n",
        "            out = self.bn(self.deconv(self.relu(x)))\n",
        "        else:\n",
        "            out = self.deconv(self.relu(x))\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = ConvBlock(input_dim, 64, activation=False, batch_norm=False)\n",
        "        self.conv2 = ConvBlock(64, 128)\n",
        "        self.conv3 = ConvBlock(128, 256)\n",
        "        self.conv4 = ConvBlock(256, 512)\n",
        "        self.conv5 = ConvBlock(512, 512, batch_norm=False)\n",
        "\n",
        "        self.deconv1 = DeconvBlock(512, 512)\n",
        "        self.deconv2 = DeconvBlock(1024, 256)\n",
        "        self.deconv3 = DeconvBlock(512, 128)\n",
        "        self.deconv4 = DeconvBlock(256, 64)\n",
        "        self.deconv5 = DeconvBlock(128, output_dim, batch_norm=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.conv1(x)\n",
        "        enc2 = self.conv2(enc1)\n",
        "        enc3 = self.conv3(enc2)\n",
        "        enc4 = self.conv4(enc3)\n",
        "        enc5 = self.conv5(enc4)\n",
        "\n",
        "        dec1 = self.deconv1(enc5)\n",
        "        dec1 = torch.cat([dec1, enc4], 1)\n",
        "        dec2 = self.deconv2(dec1)\n",
        "        dec2 = torch.cat([dec2, enc3], 1)\n",
        "        dec3 = self.deconv3(dec2)\n",
        "        dec3 = torch.cat([dec3, enc2], 1)\n",
        "        dec4 = self.deconv4(dec3)\n",
        "        dec4 = torch.cat([dec4, enc1], 1)\n",
        "        dec5 = self.deconv5(dec4)\n",
        "        out = torch.nn.Tanh()(dec5)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(input_dim, 64, activation=False, batch_norm=False)\n",
        "        self.conv2 = ConvBlock(64, 128)\n",
        "        self.conv3 = ConvBlock(128, 256)\n",
        "        self.conv4 = ConvBlock(256, 512, stride=1)\n",
        "        self.conv5 = ConvBlock(512, 1, stride=1, batch_norm=False)\n",
        "\n",
        "    def forward(self, x, label):\n",
        "        x = torch.cat([x, label], 1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        out = torch.nn.Sigmoid()(x)\n",
        "        return out\n",
        "\n",
        "    def normal_weight_init(self, mean=0.0, std=0.02):\n",
        "        for m in self.children():\n",
        "            if isinstance(m, ConvBlock):\n",
        "                torch.nn.init.normal(m.conv.weight, mean, std)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXiugLGJurML"
      },
      "source": [
        "import torch.utils.data as data\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class loadData(data.Dataset):\n",
        "    def __init__(self, image_dir, subfolder, transform):\n",
        "        super(loadData, self).__init__()\n",
        "        self.input_path = os.path.join(image_dir, subfolder)\n",
        "        self.image_filenames = [x for x in sorted(os.listdir(self.input_path))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        fileim = os.path.join(self.input_path, self.image_filenames[index])\n",
        "        img = Image.open(fileim)\n",
        "        \n",
        "        image = img.crop((0, 0, img.width // 2, img.height))\n",
        "        templ = img.crop((img.width // 2, 0, img.width, img.height))\n",
        "        \n",
        "        image = self.transform(image)\n",
        "        templ = self.transform(templ)\n",
        "\n",
        "        return templ, image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "j9-Hckt6ng9k",
        "outputId": "0f4a8010-84a1-45cc-b6a0-4932466dd7b0"
      },
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                  transforms.ToTensor(),\n",
        "                 transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "path_to_data = '/content/drive/MyDrive/datasets/facades/'\n",
        "\n",
        "train_data = loadData(path_to_data, 'train', transform)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                                batch_size=batch_size,\n",
        "                                                shuffle=True)\n",
        "\n",
        "test_data = loadData(path_to_data, 'test', transform)\n",
        "test_data_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=False)\n",
        "\n",
        "\n",
        "G = Generator(3, 3)\n",
        "D = Discriminator(6)\n",
        "G.cuda()\n",
        "D.cuda()\n",
        "\n",
        "BCE_loss = torch.nn.BCELoss().cuda()\n",
        "L1_loss = torch.nn.L1Loss().cuda()\n",
        "\n",
        "lr, beta1, beta2 = 0.0002, 0.5, 0.999\n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "\n",
        "batches_done = 0\n",
        "\n",
        "num_epochs = 300\n",
        "\n",
        "D_losses = []\n",
        "G_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "    for i, (input, target) in enumerate(train_data_loader):\n",
        "\n",
        "        x_ = Variable(input.cuda())\n",
        "        y_ = Variable(target.cuda())\n",
        "\n",
        "        # подаем реальные данные\n",
        "        D_real = D(x_, y_).squeeze()\n",
        "        real_ = Variable(torch.ones(D_real.size()).cuda())\n",
        "        D_real_loss = BCE_loss(D_real, real_)\n",
        "\n",
        "        # подаем сгенерированные данные\n",
        "        gen_image = G(x_)\n",
        "        D_fake = D(x_, gen_image).squeeze()\n",
        "        fake_ = Variable(torch.zeros(D_fake.size()).cuda())\n",
        "        D_fake_loss = BCE_loss(D_fake, fake_)\n",
        "\n",
        "        # пропагиируем дискриминатор\n",
        "        D_loss = D_real_loss + D_fake_loss\n",
        "        D.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_optimizer.step()\n",
        "\n",
        "        # тренеруем генератор\n",
        "        gen_image = G(x_)\n",
        "        D_fake_decision = D(x_, gen_image).squeeze()\n",
        "        G_fake_loss = BCE_loss(D_fake_decision, real_)\n",
        "\n",
        "        l1_loss = 100 * L1_loss(gen_image, y_)\n",
        "\n",
        "        # пропагиируем генератор\n",
        "        G_loss = G_fake_loss + l1_loss\n",
        "        G.zero_grad()\n",
        "        G_loss.backward()\n",
        "        G_optimizer.step()\n",
        "\n",
        "        D_losses.append(D_loss.data.item())\n",
        "        G_losses.append(G_loss.data.item())\n",
        "        print(\"\\t...epoch %d/%d\\tbatch %d/%d\\tD loss: %.6f\\tG loss: %.6f\" % \\\n",
        "                      (epoch, num_epochs, i, len(train_data_loader),  D_loss.data.item(), G_loss.data.item()))\n",
        "\n",
        "        batches_done += 1\n",
        "\n",
        "        if batches_done % 100 == 0:\n",
        "                gen_imgs = G(x_)\n",
        "                gen_imgs = gen_image.cpu().data\n",
        "                save_image(gen_imgs.data[:5], \"%s/%05d.png\" % (path_to_data + \"/out/\", batches_done), nrow=5, normalize=True)\n",
        "\n",
        "    plot_losses(D_losses,G_losses )\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ddeff45ab297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CFixtO-0w6x"
      },
      "source": [
        "for i, (input, target) in enumerate(test_data_loader):\n",
        "          x_ = Variable(input.cuda())\n",
        "          y_ = Variable(target.cuda())\n",
        "          gen_imgs = G(x_)\n",
        "          gen_imgs = gen_image.cpu().data\n",
        "          save_image(gen_imgs.data[:], \"%s/%05d.png\" % (path_to_data + \"/result/\", batches_done), nrow=500, normalize=True)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGSq1n7BrhrF"
      },
      "source": [
        "## CycleGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFugzR5Repy7"
      },
      "source": [
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(input_dim, 64, activation=False, batch_norm=False)\n",
        "        self.conv2 = ConvBlock(64, 128)\n",
        "        self.conv3 = ConvBlock(128, 256)\n",
        "        self.conv4 = ConvBlock(256, 512, stride=1)\n",
        "        self.conv5 = ConvBlock(512, 1, stride=1, batch_norm=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        out = torch.nn.Sigmoid()(x)\n",
        "        return out\n",
        "\n",
        "    def normal_weight_init(self, mean=0.0, std=0.02):\n",
        "        for m in self.children():\n",
        "            if isinstance(m, ConvBlock):\n",
        "                torch.nn.init.normal(m.conv.weight, mean, std)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvKKB_1CuMrp"
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGJsRsxFuOcN",
        "outputId": "31f20c40-5938-4750-f4de-538fb3e40cab"
      },
      "source": [
        "summary(Discriminator(3).cuda(),(3, 256, 256))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           3,136\n",
            "         ConvBlock-2         [-1, 64, 128, 128]               0\n",
            "         LeakyReLU-3         [-1, 64, 128, 128]               0\n",
            "            Conv2d-4          [-1, 128, 64, 64]         131,200\n",
            "       BatchNorm2d-5          [-1, 128, 64, 64]             256\n",
            "         ConvBlock-6          [-1, 128, 64, 64]               0\n",
            "         LeakyReLU-7          [-1, 128, 64, 64]               0\n",
            "            Conv2d-8          [-1, 256, 32, 32]         524,544\n",
            "       BatchNorm2d-9          [-1, 256, 32, 32]             512\n",
            "        ConvBlock-10          [-1, 256, 32, 32]               0\n",
            "        LeakyReLU-11          [-1, 256, 32, 32]               0\n",
            "           Conv2d-12          [-1, 512, 31, 31]       2,097,664\n",
            "      BatchNorm2d-13          [-1, 512, 31, 31]           1,024\n",
            "        ConvBlock-14          [-1, 512, 31, 31]               0\n",
            "        LeakyReLU-15          [-1, 512, 31, 31]               0\n",
            "           Conv2d-16            [-1, 1, 30, 30]           8,193\n",
            "        ConvBlock-17            [-1, 1, 30, 30]               0\n",
            "================================================================\n",
            "Total params: 2,766,529\n",
            "Trainable params: 2,766,529\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 63.03\n",
            "Params size (MB): 10.55\n",
            "Estimated Total Size (MB): 74.33\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2XlDz0Wrlin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097c3377-59a2-4ba6-f942-869e8f61cc65"
      },
      "source": [
        "\n",
        "from torchvision.utils import save_image\n",
        "import itertools\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                  transforms.ToTensor(),\n",
        "                 transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "path_to_data = '/content/drive/MyDrive/datasets/facades/'\n",
        "\n",
        "train_data = loadData(path_to_data, 'train', transform)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                                batch_size=batch_size,\n",
        "                                                shuffle=True)\n",
        "\n",
        "test_data = loadData(path_to_data, 'test', transform)\n",
        "test_data_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=False)\n",
        "\n",
        "\n",
        "GA2B = Generator(3, 3)\n",
        "DA = Discriminator(3)\n",
        "GB2A = Generator(3, 3)\n",
        "DB = Discriminator(3)\n",
        "\n",
        "GA2B.cuda()\n",
        "DA.cuda()\n",
        "GB2A.cuda()\n",
        "DB.cuda()\n",
        "\n",
        "cycle_loss = torch.nn.L1Loss().cuda()\n",
        "identity_loss = torch.nn.L1Loss().cuda()\n",
        "adversarial_loss = torch.nn.MSELoss().cuda()\n",
        "\n",
        "identity_losses = []\n",
        "gan_losses = []\n",
        "cycle_losses = []\n",
        "\n",
        "lr, beta1, beta2 = 0.0002, 0.5, 0.999\n",
        "\n",
        "G_optimizer = torch.optim.Adam(itertools.chain(GA2B.parameters(), \n",
        "                GB2A.parameters()), lr=lr, betas=(beta1, beta2))\n",
        "\n",
        "DA_optimizer = torch.optim.Adam(DA.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "DB_optimizer = torch.optim.Adam(DB.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "\n",
        "batches_done = 0\n",
        "\n",
        "num_epochs = 100\n",
        "D_losses = []\n",
        "G_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (input, target) in enumerate(train_data_loader):\n",
        "\n",
        "        A_ = Variable(input.cuda())\n",
        "        B_ = Variable(target.cuda())\n",
        "\n",
        "        real_ = Variable(torch.ones(DA(A_).squeeze().size()).cuda())\n",
        "        fake_ = Variable(torch.zeros(DA(A_).squeeze().size()).cuda())\n",
        "\n",
        "        G_optimizer.zero_grad()\n",
        "        # identity loss\n",
        "        identity_image_A = GB2A(A_)\n",
        "        loss_identity_A = identity_loss(identity_image_A, A_) * 5.0\n",
        "\n",
        "        identity_image_B = GA2B(B_)\n",
        "        loss_identity_B = identity_loss(identity_image_B, B_) * 5.0\n",
        "\n",
        "        # GAN loss\n",
        "        fake_A = GB2A(B_)\n",
        "        fake_output_A = DA(fake_A)\n",
        "        loss_GAN_B2A = adversarial_loss(fake_output_A, real_)\n",
        "\n",
        "        fake_B = GA2B(A_)\n",
        "        fake_output_B = DB(fake_B)\n",
        "        loss_GAN_A2B = adversarial_loss(fake_output_B, real_)\n",
        "\n",
        "        # Cycle loss\n",
        "        recovered_A = GB2A(fake_B)\n",
        "        loss_cycle_ABA = cycle_loss(recovered_A, A_) * 10.0\n",
        "\n",
        "        recovered_B = GA2B(fake_A)\n",
        "        loss_cycle_BAB = cycle_loss(recovered_B, B_) * 10.0\n",
        "\n",
        "        errG = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
        "        \n",
        "        print(loss_identity_A, loss_identity_B, loss_GAN_A2B,loss_GAN_B2A,loss_cycle_ABA, loss_cycle_BAB )\n",
        "        errG.backward()\n",
        "\n",
        "\n",
        "        G_optimizer.step()\n",
        "\n",
        "        # DA discr\n",
        "        DA_optimizer.zero_grad()\n",
        "\n",
        "        real_output_A = DA(A_)\n",
        "        errD_real_A = adversarial_loss(real_output_A, real_)\n",
        "\n",
        "        fake_output_A = DA(fake_A.detach())\n",
        "        errD_fake_A = adversarial_loss(fake_output_A, fake_)\n",
        "\n",
        "        errD_A = errD_real_A + errD_fake_A\n",
        "\n",
        "        errD_A.backward()\n",
        "        DA_optimizer.step()\n",
        "\n",
        "        # DB discr\n",
        "        DB_optimizer.zero_grad()\n",
        "\n",
        "        real_output_B = DB(B_)\n",
        "        errD_real_B = adversarial_loss(real_output_B, real_)\n",
        "\n",
        "        fake_output_B = DB(fake_B.detach())\n",
        "        errD_fake_B = adversarial_loss(fake_output_B, fake_)\n",
        "\n",
        "        errD_B = errD_real_B + errD_fake_B\n",
        "\n",
        "        errD_B.backward()\n",
        "        DB_optimizer.step()\n",
        "\n",
        "        D_loss = (errD_A + errD_B).data.item()\n",
        "        G_loss = errG.data.item()\n",
        "        D_losses.append(D_loss)\n",
        "        G_losses.append(G_loss)\n",
        "        print(\"\\t...epoch %d/%d\\tbatch %d/%d\\tD loss: %.6f\\tG loss: %.6f\" % \\\n",
        "                      (epoch, num_epochs, i, len(train_data_loader),  D_loss, G_loss))\n",
        "\n",
        "        batches_done += 1\n",
        "\n",
        "        if batches_done % 100 == 0:\n",
        "                gen_imgs = GA2B(A_)\n",
        "                gen_imgs = gen_imgs.cpu().data\n",
        "                save_image(gen_imgs.data, \"%s/%05d.png\" % (path_to_data + \"/resultCycle/\", batches_done), nrow=5, normalize=True)\n",
        "\n",
        "    plot_losses(D_losses,G_losses )\n",
        "\n",
        "\n",
        "for i, (input, target) in enumerate(test_data_loader):\n",
        "          x_ = Variable(input.cuda())\n",
        "          y_ = Variable(target.cuda())\n",
        "          gen_imgs = GA2B(x_)\n",
        "          gen_imgs = gen_imgs.cpu().data\n",
        "          save_image(gen_imgs.data[:], \"%s/%05d.png\" % (path_to_data + \"/resultCycle/\", batches_done), nrow=500, normalize=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([32, 30, 30])) that is different to the input size (torch.Size([32, 1, 30, 30])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(4.1361, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.0668, device='cuda:0', grad_fn=<MulBackward0>) tensor(0.1954, device='cuda:0', grad_fn=<MseLossBackward>) tensor(0.2253, device='cuda:0', grad_fn=<MseLossBackward>) tensor(8.3499, device='cuda:0', grad_fn=<MulBackward0>) tensor(6.3965, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "\t...epoch 0/100\tbatch 0/13\tD loss: 1.044509\tG loss: 22.369915\n",
            "tensor(3.5529, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.6999, device='cuda:0', grad_fn=<MulBackward0>) tensor(0.3665, device='cuda:0', grad_fn=<MseLossBackward>) tensor(0.3553, device='cuda:0', grad_fn=<MseLossBackward>) tensor(7.0710, device='cuda:0', grad_fn=<MulBackward0>) tensor(5.6694, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "\t...epoch 0/100\tbatch 1/13\tD loss: 1.052587\tG loss: 19.715008\n",
            "tensor(3.1060, device='cuda:0', grad_fn=<MulBackward0>) tensor(2.3870, device='cuda:0', grad_fn=<MulBackward0>) tensor(0.4467, device='cuda:0', grad_fn=<MseLossBackward>) tensor(0.3913, device='cuda:0', grad_fn=<MseLossBackward>) tensor(6.0660, device='cuda:0', grad_fn=<MulBackward0>) tensor(4.8185, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "\t...epoch 0/100\tbatch 2/13\tD loss: 1.073570\tG loss: 17.215439\n",
            "tensor(2.7601, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.9870, device='cuda:0', grad_fn=<MulBackward0>) tensor(0.4973, device='cuda:0', grad_fn=<MseLossBackward>) tensor(0.3805, device='cuda:0', grad_fn=<MseLossBackward>) tensor(5.2898, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.9866, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "\t...epoch 0/100\tbatch 3/13\tD loss: 0.931442\tG loss: 14.901279\n",
            "tensor(2.4968, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.8323, device='cuda:0', grad_fn=<MulBackward0>) tensor(0.5318, device='cuda:0', grad_fn=<MseLossBackward>) tensor(0.3276, device='cuda:0', grad_fn=<MseLossBackward>) tensor(4.8120, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.6314, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "\t...epoch 0/100\tbatch 4/13\tD loss: 0.903282\tG loss: 13.631746\n",
            "tensor(2.2356, device='cuda:0', grad_fn=<MulBackward0>) tensor(1.5894, device='cuda:0', grad_fn=<MulBackward0>) tensor(0.6162, device='cuda:0', grad_fn=<MseLossBackward>) tensor(0.3204, device='cuda:0', grad_fn=<MseLossBackward>) tensor(4.2177, device='cuda:0', grad_fn=<MulBackward0>) tensor(3.1761, device='cuda:0', grad_fn=<MulBackward0>)\n",
            "\t...epoch 0/100\tbatch 5/13\tD loss: 0.804851\tG loss: 12.155443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDgN8uJIy79z"
      },
      "source": [
        "for i, (input, target) in enumerate(test_data_loader):\n",
        "          x_ = Variable(input.cuda())\n",
        "          y_ = Variable(target.cuda())\n",
        "          gen_imgs = GA2B(x_)\n",
        "          gen_imgs = gen_image.cpu().data\n",
        "          save_image(gen_imgs.data[:], \"Cycle%s/%05d.png\" % (path_to_data + \"/result/\", batches_done), nrow=500, normalize=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}